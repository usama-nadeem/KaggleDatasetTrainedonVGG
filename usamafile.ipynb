{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade --ignore-installed kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/student/.kaggle’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 600 ~/.kaggle/kaggle.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intel-image-classification.zip: Skipping, found more recently modified local copy (use --force to force download)\r\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d puneet6060/intel-image-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AzureML\t\t\t  julia\r\n",
      " MMLSpark\t\t\t  kaggle.json\r\n",
      " SparkML\t\t\t  pytorch\r\n",
      "'Untitled Folder'\t\t  seg_pred\r\n",
      " Untitled.ipynb\t\t\t  seg_test\r\n",
      " catboost\t\t\t  seg_train\r\n",
      " h2o\t\t\t\t  usamafile.ipynb\r\n",
      " intel-image-classification.zip   vgg_transfer_trained_wts.h5\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q intel-image-classification.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AzureML\t    h2o\t\t\t\t     seg_pred\r\n",
      " MMLSpark\t    intel-image-classification.zip   seg_test\r\n",
      " SparkML\t    julia\t\t\t     seg_train\r\n",
      "'Untitled Folder'   kaggle.json\t\t\t     usamafile.ipynb\r\n",
      " catboost\t    pytorch\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from imutils import paths\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tqdm import tqdm\n",
    "def load_data(data_dir):\n",
    "  data = []\n",
    "  labels = []\n",
    "  class_dirs = os.listdir(data_dir)\n",
    "  \n",
    "  for direc in class_dirs:\n",
    "    class_dir = os.path.join(data_dir, direc)\n",
    "    for imagepath in tqdm(list(paths.list_images(class_dir))):\n",
    "      image = cv2.imread(imagepath)\n",
    "      image = cv2.resize(image, (150, 150))  # incase images not of same size\n",
    "      data.append(image)\n",
    "      labels.append(direc)\n",
    "  # normalizing and converting to numpy array format\n",
    "  data = np.array(data, dtype='float')/255.0\n",
    "  labels = np.array(labels)\n",
    "  return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 105/2271 [00:00<00:02, 1048.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2271/2271 [00:02<00:00, 985.71it/s]\n",
      "100%|██████████| 2382/2382 [00:02<00:00, 1093.24it/s]\n",
      "100%|██████████| 2404/2404 [00:02<00:00, 1124.74it/s]\n",
      "100%|██████████| 2512/2512 [00:01<00:00, 1278.05it/s]\n",
      "100%|██████████| 2274/2274 [00:01<00:00, 1239.83it/s]\n",
      "100%|██████████| 2191/2191 [00:02<00:00, 947.31it/s] \n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      " 20%|██        | 95/474 [00:00<00:00, 949.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading test images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 474/474 [00:00<00:00, 934.98it/s]\n",
      "100%|██████████| 501/501 [00:00<00:00, 1076.37it/s]\n",
      "100%|██████████| 553/553 [00:00<00:00, 1228.06it/s]\n",
      "100%|██████████| 525/525 [00:00<00:00, 1144.48it/s]\n",
      "100%|██████████| 510/510 [00:00<00:00, 1234.30it/s]\n",
      "100%|██████████| 437/437 [00:00<00:00, 1092.11it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dir = \"seg_train/seg_train\"\n",
    "test_dir = \"seg_test/seg_test\"\n",
    "pred_dir = \"data/intel-image-classification-mini/seg_pred/\"\n",
    "\n",
    "print('loading train images')\n",
    "X_train, y_train = load_data(train_dir)\n",
    "\n",
    "print('loading test images')\n",
    "X_test, y_test = load_data(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14034, 150, 150, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(y_train)\n",
    "y_test = lb.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Conv2D, Dense, MaxPooling2D, Flatten, Dropout\n",
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "vgg16 = Sequential()\n",
    "vgg16.add(Conv2D(64, kernel_size=3, padding='same', activation='relu',\n",
    "                 input_shape=(150, 150, 3)))\n",
    "vgg16.add(Conv2D(64, kernel_size=3, padding='same', activation='relu'))\n",
    "vgg16.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "vgg16.add(Dropout(0.25))\n",
    "\n",
    "vgg16.add(Conv2D(128, kernel_size=3, padding='same', activation='relu'))\n",
    "vgg16.add(Conv2D(128, kernel_size=3, padding='same', activation='relu'))\n",
    "vgg16.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "vgg16.add(Dropout(0.25))\n",
    "\n",
    "vgg16.add(Conv2D(256, kernel_size=3, padding='same', activation='relu'))\n",
    "vgg16.add(Conv2D(256, kernel_size=3, padding='same', activation='relu'))\n",
    "vgg16.add(Conv2D(256, kernel_size=3, padding='same', activation='relu'))\n",
    "vgg16.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "vgg16.add(Dropout(0.25))\n",
    "\n",
    "vgg16.add(Conv2D(512, kernel_size=3, padding='same', activation='relu'))\n",
    "vgg16.add(Conv2D(512, kernel_size=3, padding='same', activation='relu'))\n",
    "vgg16.add(Conv2D(512, kernel_size=3, padding='same', activation='relu'))\n",
    "vgg16.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "vgg16.add(Dropout(0.25))\n",
    "\n",
    "vgg16.add(Conv2D(512, kernel_size=3, activation='relu'))\n",
    "vgg16.add(Conv2D(512, kernel_size=3, activation='relu'))\n",
    "vgg16.add(Conv2D(512, kernel_size=3, activation='relu'))\n",
    "vgg16.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "vgg16.add(Dropout(0.25))\n",
    "\n",
    "vgg16.add(Flatten())\n",
    "\n",
    "vgg16.add(Dense(4096, activation='relu'))\n",
    "vgg16.add(Dense(4096, activation='relu'))\n",
    "vgg16.add(Dense(4096, activation='relu'))\n",
    "\n",
    "# the data we are using has 3 classes\n",
    "vgg16.add(Dense(6, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "(X_train, X_valid, y_train, y_valid)= train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "aug = ImageDataGenerator(\n",
    "\t\trescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "sgd = SGD(lr=0.001, decay=1e-7, momentum=.9)\n",
    "vgg16.compile(loss='categorical_crossentropy', \n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "56/56 [==============================] - 1441s 26s/step - loss: 1.7917 - accuracy: 0.1623 - val_loss: 1.7917 - val_accuracy: 0.1786\n",
      "Epoch 2/10\n",
      "56/56 [==============================] - 1866s 33s/step - loss: 1.7914 - accuracy: 0.1823 - val_loss: 1.7917 - val_accuracy: 0.1786\n",
      "Epoch 3/10\n",
      "56/56 [==============================] - 1912s 34s/step - loss: 1.7910 - accuracy: 0.1772 - val_loss: 1.7917 - val_accuracy: 0.1786\n",
      "Epoch 4/10\n",
      "56/56 [==============================] - 1920s 34s/step - loss: 1.7908 - accuracy: 0.1873 - val_loss: 1.7917 - val_accuracy: 0.1786\n",
      "Epoch 5/10\n",
      "56/56 [==============================] - 1908s 34s/step - loss: 1.7908 - accuracy: 0.1801 - val_loss: 1.7919 - val_accuracy: 0.1786\n",
      "Epoch 6/10\n",
      "56/56 [==============================] - 1952s 35s/step - loss: 1.7906 - accuracy: 0.1737 - val_loss: 1.7919 - val_accuracy: 0.1786\n",
      "Epoch 7/10\n",
      "56/56 [==============================] - 1903s 34s/step - loss: 1.7905 - accuracy: 0.1804 - val_loss: 1.7920 - val_accuracy: 0.1786\n",
      "Epoch 8/10\n",
      "56/56 [==============================] - 1938s 35s/step - loss: 1.7912 - accuracy: 0.1774 - val_loss: 1.7920 - val_accuracy: 0.1786\n",
      "Epoch 9/10\n",
      "56/56 [==============================] - 1876s 34s/step - loss: 1.7911 - accuracy: 0.1793 - val_loss: 1.7921 - val_accuracy: 0.1786\n",
      "Epoch 10/10\n",
      "56/56 [==============================] - 1986s 36s/step - loss: 1.7910 - accuracy: 0.1754 - val_loss: 1.7922 - val_accuracy: 0.1786\n"
     ]
    }
   ],
   "source": [
    "H = vgg16.fit(\n",
    "\tx=aug.flow(X_train, y_train, batch_size=128),\n",
    "\tvalidation_data=(X_valid, y_valid),\n",
    "\tsteps_per_epoch=len(X_train) // 128,\n",
    "\tepochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model's trained weights\n",
    "vgg16.save_weights('vgg16_transfer_learning.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
